---
title: "ML_Problem_Proposal_Wine"
author: "Shivam Patel, Ethan Gruis, Ben Siglow"
date: "10/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggdark)
```


Load in the data

```{r}
link <- 'https://www.dropbox.com/s/mjj5x2n2wfjxqs9/BordeauxWines.csv?dl=1'
wine_data <- read_csv(link, locale = readr::locale(encoding = "latin1"))
```

```{r}
# summary(wine_data)
# str(wine_data)
```

# Mutate our variables into factors

```{r}
wine_cols <- c(5:989)
wine_data[,wine_cols] <- lapply(wine_data[,wine_cols], factor)
#wine_data[,wine_cols] <- lapply(wine_data[,wine_cols], factor, level = c(0, 1))

# ISSUE: when factorized, wine sometimes has columns with only 1 factor, this selects only columns with multiple factors and drops the rest
wine_fixed <- wine_data[, sapply(wine_data, function(col) length(unique(col))) > 1]

# str(wine_fixed, list.len=ncol(wine_fixed))
```

Remove dollar signs from Price.

```{r}
wine_fixed$Price <- str_replace(wine_fixed$Price, "\\$", "")

wine_fixed$Price <- as.numeric(wine_fixed$Price)

colnames(wine_fixed) <- make.names(names(wine_fixed))
colnames(wine_fixed)[489] <- 'WELL.DONE.2'
# what does well done mean in terms of wine???
# look at price - some are in $/ML
```

# Visualizations

```{r}
price_score_plot <- ggplot(wine_fixed, aes(x = Price, y = Score)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), # Turn of the background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank()) +
  dark_theme_gray()

price_score_plot

score_year_plot <- ggplot(wine_fixed, aes(x = Year, y = Score)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red") +
  theme_bw() +
  theme(panel.grid.major = element_blank(), # Turn of the background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank()) +
  dark_theme_gray()

score_year_plot

hist_score_plot <- ggplot(wine_fixed, aes(x = Score)) + 
  geom_histogram(binwidth = 1, color="black", fill="white") +
  theme(panel.grid.major = element_blank(), # Turn of the background grid
    panel.grid.minor = element_blank(),
    panel.background = element_blank()) +
  xlim(70, 100) +
  dark_theme_gray()

hist_score_plot
```

# Linear regressions

```{r}
lm_1 <- lm(Score ~ Price, data = wine_fixed)

summary(lm_1)
```

```{r}
lm_2 <- lm(Score ~ Year, data = wine_fixed)

summary(lm_2)
```


```{r}
# Test glm with factors
# Doesnt work obviously
# log_fit_1 <- glm(Score ~., # Set formula
#              family=gaussian(link='identity'), # Set logistic regression
#              data= wine_fixed) # Set dataset
# summary(log_fit_1)
```

```{r}
summary(log_fit_1)
```

```{r}
library(rpart)	

tree_1 <- rpart(Score ~., # Set tree formula
                data = wine_fixed)

plotcp(tree_1) # Plot cp
```

```{r}
tree_2 <- tree_1 <- rpart(Score ~., # Set tree formula
                          data = wine_fixed, # Set data
                          control = rpart.control(cp = 0.017)) # Set parameters
```

```{r}
library(rattle)					# Fancy tree plot
library(RColorBrewer)				# Color selection for fancy tree plot

summary(tree_2)

fancyRpartPlot(tree_2)
```
## Code Borrowed From Random Forest In Parallel GitHub:
https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md

```{r}
library(randomForest)
library(caTools)





```
### NOTE: BE CAREFUL RUNNING ANYTHING BELOW THIS LINE

```{r}
library(caret)
set.seed(612)

inTraining <- createDataPartition(wine_fixed$Score, p = .75, list=FALSE)
training <- wine_fixed[inTraining,]
testing <- wine_fixed[-inTraining,]
```

```{r}
set.seed(258506) # Set random number generator seed for reproducability
# Use random forest to do bagging
bag_mod <- randomForest(Score ~., # Set tree formula
                data = training[,3:620], # Set dataset 
                ntree = 200,
                na.action=na.exclude,
                do.trace = TRUE) # Set number of trees to use
bag_mod # View model
```


```{r}
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
```

```{r}
fitControl <- trainControl(method = "cv",
                           number = 5,
                           allowParallel = TRUE)
```

Solution for NA problem: 
https://stackoverflow.com/questions/38250440/error-in-na-fail-default-missing-values-in-object-but-no-missing-values
```{r}
fit <- randomForest(Score ~., # Set tree formula
                data = training[,3:620], # Set dataset 
                ntree = 200,
                do.trace = TRUE,
                na.action=na.exclude)
```

```{r}
stopCluster(cluster)
registerDoSEQ()
```

Notes:
- XGBoost: start playing with XGBoost :)
- 







